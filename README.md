# VGDS
Video-Grounded Dialogue Systems (VGDS)<br>

Previous visual dialogue tasks focus on talking about a single static image between two agents in the conversation. However, we run into a sequence of images and audios in the real-world context like a video. Developing a dialogue system based on three different modalities: image, audio and text, is an interest topic.<br>

Talking to videos is a multi-modal dialogue task over video. Given a video includes a series video frames with audios, two agents can hold a meaningful multi-round dialog on video content in natural language. We are working on this problem now.<br>
<br>
# About me
虚步, a Ph.D. student at BUPT. My research is in the area of Vision and Language, with a focus on Visual Dialogue. I am particularly interested in building a visually-grounded conversational AI that can see the world and talk with us in natural language.<br>
<br>
Please feel free to contact me with pangweitf@bupt.edu.cn or pangweitf@163.com if you have any questions or concerns.<br>
<br>
## References
1. Hung Le, Doyen Sahoo, Nancy F. Chen, Steven C.H. Hoi. Multimodal Transformer Networks for End-to-End Video-Grounded Dialogue Systems. In ACL 2019.<br>
